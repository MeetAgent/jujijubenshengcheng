#!/usr/bin/env python3
"""
ä» Step0.1 åˆ° Step0.8 çš„ä¸€é”®è¿è¡Œè„šæœ¬ï¼ˆè·³è¿‡Step0ä¸Šä¼ ï¼‰
æ”¯æŒä»æŒ‡å®šæ­¥éª¤å¼€å§‹é‡è¯•ã€ç»Ÿè®¡tokenå’Œç”¨æ—¶ã€æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥
"""

import os
import sys
import time
import json
import argparse
from typing import Dict, List, Any, Optional

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from new_pipeline.core import PipelineConfig, PipelineUtils
from new_pipeline.core.report_generator import PipelineReportGenerator
from new_pipeline.steps.step0_1_asr import Step0_1ASR
from new_pipeline.steps.step0_2_clue_extraction import Step0_2ClueExtraction
from new_pipeline.steps.step0_3_global_alignment_llm import Step0_3GlobalAlignmentLLM
from new_pipeline.steps.step0_4_speaker_calibration import Step0_4SpeakerCalibration
from new_pipeline.steps.step0_5_integrated_analysis import Step0_5IntegratedAnalysis
from new_pipeline.steps.step0_6_plot_extraction import Step0_6PlotExtraction
from new_pipeline.steps.step0_7_script_writing import Step0_7ScriptWriting
from new_pipeline.steps.step0_8_final_script import Step0_8FinalScript

from new_pipeline.steps.commont_log import log

from dotenv import load_dotenv
load_dotenv()




class PipelineStats:
    """æµæ°´çº¿ç»Ÿè®¡ä¿¡æ¯"""
    def __init__(self):
        self.step_stats: Dict[str, Dict[str, Any]] = {}
        self.total_start_time = time.time()
    
    def start_step(self, step_name: str):
        """å¼€å§‹æ­¥éª¤è®¡æ—¶"""
        self.step_stats[step_name] = {
            "start_time": time.time(),
            "end_time": None,
            "duration": None,
            "tokens_used": 0,
            "status": "running"
        }
    
    def end_step(self, step_name: str, tokens_used: int = 0, status: str = "completed"):
        """ç»“æŸæ­¥éª¤è®¡æ—¶"""
        if step_name in self.step_stats:
            self.step_stats[step_name]["end_time"] = time.time()
            self.step_stats[step_name]["duration"] = self.step_stats[step_name]["end_time"] - self.step_stats[step_name]["start_time"]
            self.step_stats[step_name]["tokens_used"] = tokens_used
            self.step_stats[step_name]["status"] = status
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        log.info("\n" + "="*60)
        log.info("ğŸ“Š æµæ°´çº¿æ‰§è¡Œç»Ÿè®¡")
        log.info("="*60)
        
        total_duration = time.time() - self.total_start_time
        total_tokens = sum(stats.get("tokens_used", 0) for stats in self.step_stats.values())
        
        log.info(f"æ€»æ‰§è¡Œæ—¶é—´: {total_duration:.2f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
        log.info(f"æ€»Tokenæ¶ˆè€—: {total_tokens:,}")
        log.info("")
        
        for step_name, stats in self.step_stats.items():
            duration = stats.get("duration", 0)
            tokens = stats.get("tokens_used", 0)
            status = stats.get("status", "unknown")
            status_icon = "âœ…" if status == "completed" else "âŒ" if status == "failed" else "â³"
            
            log.info(f"{status_icon} {step_name}: {duration:.2f}ç§’, {tokens:,} tokens")
        
        log.info("="*60)


def check_file_integrity(config: PipelineConfig, step_name: str) -> bool:
    """æ£€æŸ¥æ­¥éª¤è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´æ€§"""
    output_root = config.project_root
    episodes = PipelineUtils.get_episode_list(output_root)
    
    # å®šä¹‰æ¯ä¸ªæ­¥éª¤çš„é¢„æœŸè¾“å‡ºæ–‡ä»¶
    expected_files = {
        "0.1": ["0_1_timed_dialogue.srt"],
        "0.2": ["0_2_clues.json"],
        "0.3": ["global_character_graph_llm.json"],
        "0.4": ["0_4_calibrated_dialogue.txt"],
        "0.5": ["0_5_dialogue_turns.json"],
        "0.6": ["0_6_script_flow.json", "0_6_script_draft.md"],
        "0.7": ["0_7_script.stmf", "0_7_script_analysis.json"],
        # 0.8 ä¸ºé›†åˆçº§åˆ«æ±‡æ€»äº§ç‰©ï¼ˆå­˜æ”¾åœ¨é›†åˆæ ¹ç›®å½• output_root ä¸‹ï¼‰
        "0.8": ["0_8_complete_screenplay.fountain", "0_8_complete_screenplay.fdx"]
    }
    
    if step_name not in expected_files:
        log.info(f"âš ï¸ æœªçŸ¥æ­¥éª¤: {step_name}")
        return True
    
    required_files = expected_files[step_name]
    missing_files = []
    
    for episode_id in episodes:
        for filename in required_files:
            if step_name == "0.3":  # å…¨å±€æ–‡ä»¶ï¼ˆåœ¨ global/ ä¸‹ï¼‰
                file_path = os.path.join(output_root, "global", filename)
            elif step_name == "0.8":  # å…¨å±€åˆå¹¶æ–‡ä»¶ï¼ˆé›†åˆæ ¹ç›®å½•ä¸‹ï¼‰
                file_path = os.path.join(output_root, filename)
            else:  # å‰§é›†æ–‡ä»¶
                file_path = os.path.join(output_root, episode_id, filename)
            
            if not os.path.exists(file_path):
                missing_files.append(f"{episode_id}/{filename}")
            else:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æŸå
                try:
                    if filename.endswith('.json'):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            json.load(f)
                    elif os.path.getsize(file_path) == 0:
                        missing_files.append(f"{episode_id}/{filename} (ç©ºæ–‡ä»¶)")
                except (json.JSONDecodeError, Exception) as e:
                    missing_files.append(f"{episode_id}/{filename} (æŸå: {e})")
    
    if missing_files:
        log.info(f"âŒ {step_name} æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥:")
        for missing in missing_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            log.info(f"   ç¼ºå°‘: {missing}")
        if len(missing_files) > 10:
            log.info(f"   ... è¿˜æœ‰ {len(missing_files) - 10} ä¸ªæ–‡ä»¶")
        return False
    
    log.info(f"âœ… {step_name} æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
    return True


def _fail(step: str, result) -> bool:
    status = (result or {}).get("status")
    if step in ("0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8"):
        return status != "completed" and status != "already_exists"
    return status != "success" and status != "already_exists"


def run_step(step_name: str, step_class, config: PipelineConfig, stats: PipelineStats) -> tuple[bool, Any, Any]:
    """è¿è¡Œå•ä¸ªæ­¥éª¤ï¼Œè¿”å› (æˆåŠŸçŠ¶æ€, æ­¥éª¤å®ä¾‹, ç»“æœ)"""
    log.info(f"\n{step_name}: {step_class.__name__} â€¦")
    stats.start_step(step_name)
    
    try:
        step_instance = step_class(config)
        result = step_instance.run()
        
        # æ£€æŸ¥æ­¥éª¤æ˜¯å¦æˆåŠŸ
        if _fail(step_name, result):
            log.info(f"âŒ {step_name} å¤±è´¥: {result}")
            stats.end_step(step_name, status="failed")
            return False, step_instance, result
        
        # æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥
        if not check_file_integrity(config, step_name):
            log.info(f"âŒ {step_name} æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥")
            stats.end_step(step_name, status="failed")
            return False, step_instance, result
        
        # å°è¯•ä»ç»“æœä¸­æå–tokenä½¿ç”¨é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        tokens_used = 0
        if isinstance(result, dict):
            tokens_used = result.get("tokens_used", 0)
        
        stats.end_step(step_name, tokens_used=tokens_used, status="completed")
        log.info(f"âœ… {step_name} å®Œæˆ")
        return True, step_instance, result
        
    except Exception as e:
        log.info(f"âŒ {step_name} å¼‚å¸¸: {e}")
        stats.end_step(step_name, status="failed")
        return False, None, {"error": str(e)}


def delete_step_files(config: PipelineConfig, step_name: str, target_episodes: List[str] = None):
    """åˆ é™¤æŒ‡å®šæ­¥éª¤çš„è¾“å‡ºæ–‡ä»¶"""
    output_root = config.project_root
    
    # å®šä¹‰æ¯ä¸ªæ­¥éª¤çš„é¢„æœŸè¾“å‡ºæ–‡ä»¶
    expected_files = {
        "0.1": ["0_1_timed_dialogue.srt"],
        "0.2": ["0_2_clues.json"],
        "0.3": ["global_character_graph_llm.json"],
        "0.4": ["0_4_calibrated_dialogue.txt"],
        "0.5": ["0_5_dialogue_turns.json"],
        "0.6": ["0_6_script_flow.json", "0_6_script_draft.md"],
        "0.7": ["0_7_script.stmf", "0_7_script_analysis.json"],
        "0.8": ["0_8_complete_screenplay.fountain", "0_8_complete_screenplay.fdx"]
    }
    
    if step_name not in expected_files:
        return
    
    required_files = expected_files[step_name]
    deleted_count = 0
    
    if target_episodes:
        episodes = target_episodes
    else:
        episodes = PipelineUtils.get_episode_list(output_root)
    
    for episode_id in episodes:
        for filename in required_files:
            if step_name == "0.3":  # å…¨å±€æ–‡ä»¶ï¼ˆåœ¨ global/ ä¸‹ï¼‰
                file_path = os.path.join(output_root, "global", filename)
            elif step_name == "0.8":  # å…¨å±€åˆå¹¶æ–‡ä»¶ï¼ˆé›†åˆæ ¹ç›®å½•ä¸‹ï¼‰
                file_path = os.path.join(output_root, filename)
            else:  # å‰§é›†æ–‡ä»¶
                file_path = os.path.join(output_root, episode_id, filename)
            
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    log.info(f"ğŸ—‘ï¸ åˆ é™¤: {file_path}")
                except Exception as e:
                    log.info(f"âŒ åˆ é™¤å¤±è´¥: {file_path} - {e}")
    
    log.info(f"âœ… åˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶")


def check_invalid_files(config: PipelineConfig, step_name: str) -> List[str]:
    """æ£€æŸ¥æŒ‡å®šæ­¥éª¤çš„æ— æ•ˆæ–‡ä»¶"""
    output_root = config.project_root
    episodes = PipelineUtils.get_episode_list(output_root)
    
    # å®šä¹‰æ¯ä¸ªæ­¥éª¤çš„é¢„æœŸè¾“å‡ºæ–‡ä»¶
    expected_files = {
        "0.1": ["0_1_timed_dialogue.srt"],
        "0.2": ["0_2_clues.json"],
        "0.3": ["global_character_graph_llm.json"],
        "0.4": ["0_4_calibrated_dialogue.txt"],
        "0.5": ["0_5_dialogue_turns.json"],
        "0.6": ["0_6_script_flow.json", "0_6_script_draft.md"],
        "0.7": ["0_7_script.stmf", "0_7_script_analysis.json"],
        "0.8": ["0_8_complete_screenplay.fountain", "0_8_complete_screenplay.fdx"]
    }
    
    if step_name not in expected_files:
        return []
    
    required_files = expected_files[step_name]
    invalid_episodes = []
    
    for episode_id in episodes:
        for filename in required_files:
            if step_name == "0.3":  # å…¨å±€æ–‡ä»¶ï¼ˆåœ¨ global/ ä¸‹ï¼‰
                file_path = os.path.join(output_root, "global", filename)
            elif step_name == "0.8":  # å…¨å±€åˆå¹¶æ–‡ä»¶ï¼ˆé›†åˆæ ¹ç›®å½•ä¸‹ï¼‰
                file_path = os.path.join(output_root, filename)
            else:  # å‰§é›†æ–‡ä»¶
                file_path = os.path.join(output_root, episode_id, filename)
            
            if not os.path.exists(file_path):
                invalid_episodes.append(episode_id)
                break
            else:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æŸå
                try:
                    if filename.endswith('.json'):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            # é’ˆå¯¹ä¸åŒæ­¥éª¤çš„ç»“æ„æ ¡éªŒ
                            if step_name == "0.5":
                                valid = False
                                if isinstance(data, dict):
                                    # æ¥å— dialogue_turnsï¼ˆä¸»ï¼‰ã€turns/dialoguesï¼ˆå…¼å®¹ï¼‰
                                    valid = bool(data.get('dialogue_turns') or data.get('turns') or data.get('dialogues'))
                                elif isinstance(data, list):
                                    valid = len(data) > 0
                                if not valid:
                                    invalid_episodes.append(episode_id)
                                    break
                            else:
                                # é€šç”¨ï¼ˆå®½æ¾ï¼‰æ ¡éªŒï¼šéç©ºå³å¯
                                if not data:
                                    invalid_episodes.append(episode_id)
                                    break
                    elif os.path.getsize(file_path) < 100:  # æ–‡ä»¶å¤ªå°
                        invalid_episodes.append(episode_id)
                        break
                except (json.JSONDecodeError, Exception):
                    invalid_episodes.append(episode_id)
                    break
    
    return invalid_episodes


def interactive_step_selection(config: PipelineConfig) -> tuple:
    """äº’åŠ¨å¼æ­¥éª¤é€‰æ‹©"""
    log.info("\n" + "="*60)
    log.info("ğŸ¯ äº’åŠ¨å¼æµæ°´çº¿é…ç½®")
    log.info("="*60)
    
    # æ£€æŸ¥å„æ­¥éª¤çš„æ–‡ä»¶çŠ¶æ€
    steps = [
        ("0.1", "ASR"),
        ("0.2", "çº¿ç´¢æå–"),
        ("0.3", "å…¨å±€è§’è‰²å¯¹é½"),
        ("0.4", "è¯´è¯äººæ ¡å‡†"),
        ("0.5", "å¯¹è¯è½®æ¬¡é‡æ„"),
        ("0.6", "æƒ…èŠ‚æŠ½å–"),
        ("0.7", "å‰§æœ¬æ’°å†™ï¼ˆSTMFï¼‰"),
        ("0.8", "åˆå¹¶ä¸å¯¼å‡º")
    ]
    
    log.info("ğŸ“Š å„æ­¥éª¤æ–‡ä»¶çŠ¶æ€æ£€æŸ¥:")
    step_status = {}
    for step_num, step_desc in steps:
        invalid_files = check_invalid_files(config, step_num)
        total_episodes = len(PipelineUtils.get_episode_list(config.project_root))
        valid_count = total_episodes - len(invalid_files)
        
        if step_num == "0.3":  # å…¨å±€æ­¥éª¤
            candidates = [
                os.path.join(config.project_root, "global", "global_character_graph_llm.json"),
                os.path.join(config.project_root, "global_character_graph_llm.json"),
            ]
            if any(os.path.exists(p) for p in candidates):
                status = "âœ… å®Œæˆ"
            else:
                status = "âŒ æœªå®Œæˆ"
        else:
            if len(invalid_files) == 0:
                status = "âœ… å®Œæˆ"
            elif len(invalid_files) == total_episodes:
                status = "âŒ æœªå¼€å§‹"
            else:
                status = f"âš ï¸ éƒ¨åˆ†å®Œæˆ ({valid_count}/{total_episodes})"
        
        step_status[step_num] = {
            "status": status,
            "invalid_files": invalid_files,
            "valid_count": valid_count,
            "total_count": total_episodes
        }
        log.info(f"  {step_num}: {step_desc} - {status}")
    
    log.info("\nğŸ® é€‰æ‹©æ‰§è¡Œæ¨¡å¼:")
    log.info("1. ä»å¤´å¼€å§‹ (é‡æ–°æ‰§è¡Œæ‰€æœ‰æ­¥éª¤)")
    log.info("2. ä»æŒ‡å®šæ­¥éª¤å¼€å§‹ (è·³è¿‡å·²å®Œæˆçš„æ­¥éª¤)")
    log.info("3. å¼ºåˆ¶é‡è·‘æŒ‡å®šæ­¥éª¤ (åˆ é™¤ç°æœ‰æ–‡ä»¶é‡æ–°æ‰§è¡Œ)")
    log.info("4. ä¿®å¤æ— æ•ˆæ–‡ä»¶ (åªé‡è·‘æœ‰é—®é¢˜çš„æ–‡ä»¶)")
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1-4): ").strip()
            if choice in ["1", "2", "3", "4"]:
                break
            log.info("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")
        except KeyboardInterrupt:
            log.info("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
            return None, None, None
    
    if choice == "1":
        return "0.1", "rerun", []
    elif choice == "2":
        log.info("\nğŸ“‹ å¯ç”¨æ­¥éª¤:")
        for step_num, step_desc in steps:
            log.info(f"  {step_num}: {step_desc}")
        
        while True:
            try:
                start_step = input("\nè¯·è¾“å…¥èµ·å§‹æ­¥éª¤ (0.1-0.8): ").strip()
                if start_step in [s[0] for s in steps]:
                    return start_step, "resume", []
                log.info("âŒ æ— æ•ˆæ­¥éª¤ï¼Œè¯·è¾“å…¥ 0.1-0.8")
            except KeyboardInterrupt:
                log.info("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
                return None, None, None
    elif choice == "3":
        log.info("\nğŸ“‹ å¯é‡è·‘çš„æ­¥éª¤:")
        for step_num, step_desc in steps:
            status_info = step_status[step_num]
            log.info(f"  {step_num}: {step_desc} - {status_info['status']}")
        
        while True:
            try:
                target_step = input("\nè¯·è¾“å…¥è¦é‡è·‘çš„æ­¥éª¤ (0.1-0.8): ").strip()
                if target_step in [s[0] for s in steps]:
                    return target_step, "force_rerun", []
                log.info("âŒ æ— æ•ˆæ­¥éª¤ï¼Œè¯·è¾“å…¥ 0.1-0.8")
            except KeyboardInterrupt:
                log.info("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
                return None, None, None
    elif choice == "4":
        log.info("\nğŸ”§ æ£€æµ‹åˆ°çš„é—®é¢˜æ–‡ä»¶:")
        problem_steps = []
        for step_num, step_desc in steps:
            status_info = step_status[step_num]
            if status_info["invalid_files"]:
                problem_steps.append(step_num)
                log.info(f"  {step_num}: {step_desc} - {len(status_info['invalid_files'])} ä¸ªé—®é¢˜æ–‡ä»¶")
        
        if not problem_steps:
            log.info("âœ… æ²¡æœ‰å‘ç°é—®é¢˜æ–‡ä»¶")
            return None, None, None
        
        while True:
            try:
                target_step = input(f"\nè¯·é€‰æ‹©è¦ä¿®å¤çš„æ­¥éª¤ ({'/'.join(problem_steps)}): ").strip()
                if target_step in problem_steps:
                    return target_step, "fix_invalid", step_status[target_step]["invalid_files"]
                log.info(f"âŒ æ— æ•ˆæ­¥éª¤ï¼Œè¯·ä» {problem_steps} ä¸­é€‰æ‹©")
            except KeyboardInterrupt:
                log.info("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
                return None, None, None


def main() -> int:
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="è¿è¡Œå‰§é›†å‰§æœ¬ç”Ÿæˆæµæ°´çº¿")
    parser.add_argument("--start-step", type=str, default="0.1", 
                       help="ä»æŒ‡å®šæ­¥éª¤å¼€å§‹ (0.1-0.8, é»˜è®¤: 0.1)")
    parser.add_argument("--collection", type=str, 
                       help="è¾“å‡ºé›†åˆåç§° (è¦†ç›–ç¯å¢ƒå˜é‡)")
    parser.add_argument("--bucket", type=str,
                       help="GCSå­˜å‚¨æ¡¶åç§° (è¦†ç›–ç¯å¢ƒå˜é‡)")
    parser.add_argument("--skip-integrity-check", action="store_true",
                       help="è·³è¿‡æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥")
    parser.add_argument("--interactive", action="store_true",
                       help="å¯ç”¨äº’åŠ¨å¼æ¨¡å¼")
    parser.add_argument("--force-rerun", action="store_true",
                       help="å¼ºåˆ¶é‡è·‘æŒ‡å®šæ­¥éª¤")
    parser.add_argument("--fix-invalid", action="store_true",
                       help="åªä¿®å¤æ— æ•ˆæ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦æ²¡æœ‰ä¼ å…¥ä»»ä½•å‚æ•°
    if len(sys.argv) == 1:
        log.info("ğŸ¬ å‰§é›†å‰§æœ¬ç”Ÿæˆæµæ°´çº¿")
        log.info("="*60)
        log.info("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
        log.info("  æœ¬å·¥å…·æ”¯æŒä» Step 0.1 åˆ° Step 0.8 çš„å®Œæ•´æµæ°´çº¿æ‰§è¡Œ")
        log.info("")
        log.info("ğŸš€ å¿«é€Ÿå¼€å§‹:")
        log.info("  python run_0_1_to_0_8.py --interactive")
        log.info("  (æ¨è: å¯ç”¨äº’åŠ¨å¼æ¨¡å¼ï¼Œå¼•å¯¼æ‚¨å®Œæˆé…ç½®)")
        log.info("")
        log.info("âš™ï¸ ä¸»è¦å‚æ•°:")
        log.info("  --interactive           å¯ç”¨äº’åŠ¨å¼æ¨¡å¼ (æ¨èæ–°æ‰‹ä½¿ç”¨)")
        log.info("  --collection NAME       æŒ‡å®šè¾“å‡ºé›†åˆåç§°")
        log.info("  --start-step STEP       ä»æŒ‡å®šæ­¥éª¤å¼€å§‹ (0.1-0.8)")
        log.info("  --force-rerun          å¼ºåˆ¶é‡è·‘æŒ‡å®šæ­¥éª¤")
        log.info("  --fix-invalid          åªä¿®å¤æ— æ•ˆæ–‡ä»¶")
        log.info("  --skip-integrity-check  è·³è¿‡æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥")
        log.info("  --bucket NAME          GCSå­˜å‚¨æ¡¶åç§°")
        log.info("")
        log.info("ğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        log.info("  # äº’åŠ¨å¼è¿è¡Œ (æ¨è)")
        log.info("  python run_0_1_to_0_8.py --interactive")
        log.info("")
        log.info("  # ä»å¤´å¼€å§‹è¿è¡ŒæŒ‡å®šé›†åˆ")
        log.info("  python run_0_1_to_0_8.py --collection æˆ‘çš„å‰§æœ¬é›†åˆ")
        log.info("")
        log.info("  # ä»æŒ‡å®šæ­¥éª¤å¼€å§‹")
        log.info("  python run_0_1_to_0_8.py --collection æˆ‘çš„å‰§æœ¬é›†åˆ --start-step 0.5")
        log.info("")
        log.info("  # å¼ºåˆ¶é‡è·‘æŸä¸ªæ­¥éª¤")
        log.info("  python run_0_1_to_0_8.py --collection æˆ‘çš„å‰§æœ¬é›†åˆ --start-step 0.6 --force-rerun")
        log.info("")
        log.info("ğŸ’¡ æç¤º: ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å‚æ•°è¯´æ˜")
        log.info("="*60)
        return 0
    
    args = parser.parse_args()
    
    # è¯»å–é›†åˆåç§°ï¼ˆäº’åŠ¨æ¨¡å¼ä¸‹å…è®¸äº¤äº’é€‰æ‹©ï¼‰
    collection = args.collection or os.environ.get("STEP0_COLLECTION", "").strip()
    if args.interactive and not collection:
        # åœ¨ new_pipeline/output ä¸‹åˆ—å‡ºå€™é€‰é›†åˆç›®å½•ï¼ˆæ”¯æŒåŒå±‚åŒåæˆ–å•å±‚åŒ…å« episode_*/global çš„ç›®å½•ï¼‰
        base_output_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), "new_pipeline", "output"))
        candidates = []
        try:
            for name in sorted(os.listdir(base_output_dir)):
                outer_path = os.path.join(base_output_dir, name)
                if not os.path.isdir(outer_path):
                    continue
                inner_same = os.path.isdir(os.path.join(outer_path, name))
                has_global = os.path.isdir(os.path.join(outer_path, "global"))
                has_episode = False
                try:
                    for d in os.listdir(outer_path):
                        if d.startswith("episode_") and os.path.isdir(os.path.join(outer_path, d)):
                            has_episode = True
                            break
                except Exception:
                    pass
                if inner_same or has_global or has_episode:
                    candidates.append(name)
        except FileNotFoundError:
            candidates = []
        if not candidates:
            log.info("âŒ æœªæ‰¾åˆ°å¯ç”¨é›†åˆç›®å½•ï¼Œè¯·ä½¿ç”¨ --collection æŒ‡å®šæˆ–å…ˆç”Ÿæˆè¾“å‡º")
            return 1
        log.info("\nğŸ“‚ å¯ç”¨é›†åˆç›®å½•ï¼š")
        for idx, name in enumerate(candidates, 1):
            log.info(f"  {idx}. {name}")
        while True:
            try:
                sel = input("\nè¯·è¾“å…¥è¦ä½¿ç”¨çš„é›†åˆç¼–å·: ").strip()
                if sel.isdigit() and 1 <= int(sel) <= len(candidates):
                    collection = candidates[int(sel) - 1]
                    break
                log.info("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥æœ‰æ•ˆç¼–å·")
            except KeyboardInterrupt:
                log.info("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
                return 1
    if not collection:
        log.info("âŒ ç¼ºå°‘é›†åˆåç§°ï¼Œè¯·ä½¿ç”¨ --collection å‚æ•°æˆ–è®¾ç½® STEP0_COLLECTION ç¯å¢ƒå˜é‡")
        return 1

    # é…ç½®
    config = PipelineConfig()
    base_output_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), "new_pipeline", "output"))
    outer_path = os.path.join(base_output_dir, collection)
    inner_same_path = os.path.join(outer_path, collection)
    # å…¼å®¹åŒå±‚ä¸å•å±‚ç›®å½•ç»“æ„
    if os.path.isdir(inner_same_path):
        output_root = os.path.abspath(inner_same_path)
    else:
        output_root = os.path.abspath(outer_path)
    os.makedirs(output_root, exist_ok=True)

    # å…è®¸å¤–éƒ¨è¦†ç›– bucket
    bucket_name = args.bucket or os.environ.get("STEP0_BUCKET_NAME")
    if bucket_name:
        config.config.setdefault("gcp", {})
        config.config["gcp"]["bucket_name"] = bucket_name

    config.config.setdefault("project", {})
    config.config["project"]["root_dir"] = output_root
    config.config["project"]["output_dir"] = output_root

    # æ£€æŸ¥è¾“å…¥ç›®å½•ï¼Œroot_dir
    log.info(f"é¡¹ç›®æ ¹ç›®å½•: {config.project_root}, è¾“å‡ºç›®å½•: {config.output_dir}")


    # äº’åŠ¨å¼æ¨¡å¼å¤„ç†
    if args.interactive:
        result = interactive_step_selection(config)
        if result is None:
            return 1
        start_step, mode, target_episodes = result
    else:
        start_step = args.start_step
        if args.force_rerun:
            mode = "force_rerun"
        elif args.fix_invalid:
            mode = "fix_invalid"
            # æ£€æŸ¥æ— æ•ˆæ–‡ä»¶
            invalid_episodes = check_invalid_files(config, start_step)
            if not invalid_episodes:
                log.info(f"âœ… æ­¥éª¤ {start_step} æ²¡æœ‰æ— æ•ˆæ–‡ä»¶")
                return 0
            target_episodes = invalid_episodes
        else:
            mode = "resume"
        target_episodes = []

    log.info("="*60)
    log.info("ğŸ¬ å‰§é›†å‰§æœ¬ç”Ÿæˆæµæ°´çº¿")
    log.info("="*60)
    log.info(f"è¾“å‡ºç›®å½•: {output_root}")
    log.info(f"é›†åˆåç§°: {collection}")
    log.info(f"èµ·å§‹æ­¥éª¤: {start_step}")
    log.info(f"æ‰§è¡Œæ¨¡å¼: {mode}")
    log.info(f"è·³è¿‡å®Œæ•´æ€§æ£€æŸ¥: {args.skip_integrity_check}")
    if target_episodes:
        log.info(f"ç›®æ ‡å‰§é›†: {len(target_episodes)} ä¸ª")
    log.info("="*60)

    # åˆå§‹åŒ–ç»Ÿè®¡
    stats = PipelineStats()
    
    # å®šä¹‰æ­¥éª¤åˆ—è¡¨
    steps = [
        ("0.1", Step0_1ASR, "ASR"),
        ("0.2", Step0_2ClueExtraction, "çº¿ç´¢æå–"),
        ("0.3", Step0_3GlobalAlignmentLLM, "å…¨å±€è§’è‰²å¯¹é½"),
        ("0.4", Step0_4SpeakerCalibration, "è¯´è¯äººæ ¡å‡†"),
        ("0.5", Step0_5IntegratedAnalysis, "å¯¹è¯è½®æ¬¡é‡æ„"),
        ("0.6", Step0_6PlotExtraction, "æƒ…èŠ‚æŠ½å–"),
        ("0.7", Step0_7ScriptWriting, "å‰§æœ¬æ’°å†™ï¼ˆSTMFï¼‰"),
        ("0.8", Step0_8FinalScript, "åˆå¹¶ä¸å¯¼å‡º")
    ]
    
    # æ‰¾åˆ°èµ·å§‹æ­¥éª¤
    start_index = 0
    for i, (step_num, _, _) in enumerate(steps):
        if step_num == start_step:
            start_index = i
            break
    else:
        log.info(f"âŒ æ— æ•ˆçš„èµ·å§‹æ­¥éª¤: {start_step}")
        log.info(f"å¯ç”¨æ­¥éª¤: {', '.join([s[0] for s in steps])}")
        return 1
    
    # å¤„ç†å¼ºåˆ¶é‡è·‘æ¨¡å¼
    if mode == "force_rerun":
        log.info(f"ğŸ—‘ï¸ å¼ºåˆ¶é‡è·‘æ¨¡å¼ï¼šåˆ é™¤æ­¥éª¤ {start_step} çš„ç°æœ‰æ–‡ä»¶...")
        log.info("âš ï¸ æ³¨æ„ï¼šå¼ºåˆ¶é‡è·‘å°†åˆ é™¤ç°æœ‰æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²å¤‡ä»½é‡è¦æ•°æ®")
        delete_step_files(config, start_step, target_episodes)
    
    log.info(f"ä»æ­¥éª¤ {start_step} å¼€å§‹æ‰§è¡Œ ({mode} æ¨¡å¼)...")
    
    # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
    report_generator = PipelineReportGenerator(config)
    
    try:
        # æ‰§è¡Œæ­¥éª¤
        for i in range(start_index, len(steps)):
            step_num, step_class, step_desc = steps[i]
            step_name = f"step{step_num.replace('.', '_')}"
            
            # è®°å½•æ­¥éª¤å¼€å§‹
            report_generator.record_step_start(step_name)
            
            # å¦‚æœè·³è¿‡å®Œæ•´æ€§æ£€æŸ¥ï¼Œåˆ™ä¿®æ”¹æ£€æŸ¥å‡½æ•°
            if args.skip_integrity_check:
                global check_file_integrity
                original_check = check_file_integrity
                check_file_integrity = lambda config, step_name: True
            
            success, step_instance, step_result = run_step(step_num, step_class, config, stats)
            
            # æ¢å¤åŸå§‹æ£€æŸ¥å‡½æ•°
            if args.skip_integrity_check:
                check_file_integrity = original_check
            
            # è®°å½•æ­¥éª¤ç»“æŸï¼ˆè·å–å®¢æˆ·ç«¯tokenä½¿ç”¨ä¿¡æ¯ï¼‰
            client = getattr(step_instance, 'client', None) if step_instance else None
            report_generator.record_step_end(step_name, step_result, client)
            
            if not success:
                log.info(f"\nâŒ æµæ°´çº¿åœ¨æ­¥éª¤ {step_num} å¤±è´¥")
                stats.print_summary()
                return 1
        
        log.info("\nğŸ‰ å…¨æµç¨‹å®Œæˆ")
        stats.print_summary()
        
        # ç”Ÿæˆè¿è¡ŒæŠ¥å‘Š
        try:
            report_file = report_generator.generate_report(config.output_dir)
            log.info(f"\nğŸ“Š è¿è¡ŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        except Exception as e:
            log.info(f"\nâš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        
        return 0

    except KeyboardInterrupt:
        log.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        stats.print_summary()
        return 1
    except Exception as e:
        log.info(f"\nâŒ è¿è¡Œå¼‚å¸¸: {e}")
        stats.print_summary()
        return 1


if __name__ == "__main__":
    raise SystemExit(main())


