"""
Step0: ä¸Šä¼ å‡†å¤‡
å°†æœ¬åœ°è§†é¢‘æ–‡ä»¶ä¸Šä¼ åˆ°Google Cloud Storage
"""

import os
import glob
import time
from typing import Dict, Any, List
from google.cloud import storage
from google.cloud.exceptions import NotFound

from core import PipelineConfig, GenAIClient, PipelineUtils
from core.exceptions import StepDependencyError, FileNotFoundError
from . import PipelineStep

class Step0Upload(PipelineStep):
    """Step0: ä¸Šä¼ è§†é¢‘åˆ°GCS"""
    
    @property
    def step_number(self) -> int:
        return 0
    
    @property
    def step_name(self) -> str:
        return "upload"
    
    def check_dependencies(self, episode_id: str = None) -> bool:
        """æ£€æŸ¥ä¾èµ–"""
        # Step0æ²¡æœ‰å‰ç½®ä¾èµ–
        return True
    
    def get_output_files(self, episode_id: str = None) -> list:
        """è·å–è¾“å‡ºæ–‡ä»¶åˆ—è¡¨"""
        if episode_id:
            return [f"{episode_id}/0_gcs_path.txt"]
        return []
    
    def run(self, episode_id: str = None) -> Dict[str, Any]:
        """è¿è¡Œä¸Šä¼ æ­¥éª¤"""
        if episode_id:
            return self._run_single_episode(episode_id)
        else:
            return self._run_all_episodes()
    
    def _run_single_episode(self, episode_id: str, retry_count: int = 0) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªå‰§é›†"""
        print(f"Step0: å¤„ç† {episode_id}")
        
        # è®¡ç®—é›†åˆæ ¹ï¼ˆå¯é€‰ï¼‰ï¼šå°† gcs_path.txt å†™å…¥é›†åˆ/episode_XXX
        out_collection = os.environ.get('STEP0_OUT_COLLECTION') or ''
        base_output = os.path.abspath(os.path.join(self.config.output_dir, out_collection)) if out_collection else os.path.abspath(self.config.output_dir)
        ep_out_dir = os.path.join(base_output, episode_id)
        os.makedirs(ep_out_dir, exist_ok=True)
        output_file = os.path.join(ep_out_dir, "0_gcs_path.txt")
        
        if os.path.exists(output_file):
            print(f"âœ… {episode_id} å·²æœ‰0_gcs_path.txtï¼Œè·³è¿‡ä¸Šä¼ ")
            with open(output_file, 'r', encoding='utf-8') as f:
                gcs_path = f.read().strip()
            return {"status": "already_exists", "gcs_path": gcs_path}
        
        # ä¼˜å…ˆï¼šä»è¾“å‡ºç›®å½•è¯»å–æœ¬åœ°è§†é¢‘è·¯å¾„æ ‡è®°
        mark_file = os.path.join(ep_out_dir, "_local_mp4_path.txt")
        mp4_files = []
        if os.path.exists(mark_file):
            try:
                with open(mark_file, 'r', encoding='utf-8') as f:
                    p = f.read().strip()
                    if p and os.path.isfile(p):
                        mp4_files = [p]
            except Exception:
                pass
        # å›é€€ï¼šåœ¨ project_root/episode_xxx ä¸‹æŸ¥æ‰¾ mp4ï¼ˆè€è·¯å¾„å…¼å®¹ï¼‰
        if not mp4_files:
            episode_dir = os.path.join(self.config.project_root, episode_id)
            mp4_files = glob.glob(os.path.join(episode_dir, "*.mp4"))
        
        if not mp4_files:
            print(f"Warning: {episode_id} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°MP4æ–‡ä»¶")
            return {"status": "no_mp4_found"}
        
        mp4_file = mp4_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªMP4æ–‡ä»¶
        file_name = os.path.basename(mp4_file)
        
        # å¸¦é‡è¯•çš„ä¸Šä¼ 
        max_retries = 3
        for attempt in range(max_retries + 1):
            try:
                # ä¸Šä¼ åˆ°GCS
                gcs_path = self._upload_to_gcs(mp4_file, episode_id, file_name)
                
                # ä¿å­˜ gcs_path.txt åˆ°é›†åˆ/episode_XXX
                self.utils.save_text_file(output_file, gcs_path)
                
                print(f"âœ… {episode_id} ä¸Šä¼ å®Œæˆ: {gcs_path}")
                return {"status": "success", "gcs_path": gcs_path}
                
            except Exception as e:
                if attempt < max_retries:
                    wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š2, 4, 6ç§’
                    print(f"âš ï¸ {episode_id} ä¸Šä¼ å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ {episode_id} ä¸Šä¼ å¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡): {e}")
                    return {"status": "upload_failed", "error": str(e), "retry_count": retry_count + max_retries}
    
    def _run_all_episodes(self) -> Dict[str, Any]:
        """å¤„ç†æ‰€æœ‰å‰§é›†"""
        import re
        from concurrent.futures import ThreadPoolExecutor, as_completed
        from tqdm import tqdm
        # è¯»å–ç¯å¢ƒå‚æ•°ï¼šè¾“å…¥ç›®å½•/è¾“å‡ºé›†åˆ/æ¡¶å
        input_dir = os.environ.get('STEP0_INPUT_DIR')
        if not input_dir:
            # é€€åŒ–ï¼šä½¿ç”¨ config.project_root ä½œä¸ºè¾“å…¥æ ¹
            input_dir = self.config.project_root
        input_dir = os.path.abspath(input_dir)

        collection_name = os.environ.get('STEP0_COLLECTION')
        if not collection_name:
            collection_name = os.path.basename(input_dir.rstrip(os.sep)) + "_output"

        # è¾“å‡ºæ ¹ç›®å½•ï¼šåœ¨é…ç½®çš„ output_dir ä¸‹åˆ›å»ºé›†åˆç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
        output_root = os.path.abspath(os.path.join(self.config.output_dir, collection_name))
        os.makedirs(output_root, exist_ok=True)

        # é€’å½’æœç´¢è¾“å…¥ç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶
        exts = {'.mp4', '.MP4', '.mov', '.MOV', '.m4v', '.M4V', '.mkv', '.MKV', '.avi', '.AVI'}
        mp4_paths = []
        for root, dirs, files in os.walk(input_dir):
            for fn in files:
                _, ext = os.path.splitext(fn)
                if ext in exts:
                    mp4_paths.append(os.path.join(root, fn))
        mp4_paths.sort()
        if not mp4_paths:
            print(f"Warning: åœ¨è¾“å…¥ç›®å½•æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {input_dir}")
            return {"status": "no_input"}

        # ä¸ºæ¯ä¸ª mp4 ç”Ÿæˆ episode_xxx åç§°ï¼šä¼˜å…ˆä½¿ç”¨æ–‡ä»¶åä¸­çš„æ•°å­—
        episodes = []
        used_ids = set()
        next_seq = 1
        import re as _re
        for p in mp4_paths:
            bn = os.path.basename(p)
            m = _re.search(r"(\d+)", bn)
            ep_num = None
            if m:
                try:
                    ep_num = int(m.group(1))
                except Exception:
                    ep_num = None
            if ep_num is None:
                # åˆ†é…é¡ºåºå·ï¼ˆé¿å¼€å·²å ç”¨ï¼‰
                while next_seq in used_ids:
                    next_seq += 1
                ep_num = next_seq
                next_seq += 1
            # å¤„ç†å†²çªï¼šè‹¥åŒå·å·²å ç”¨ï¼Œåˆ™æ‰¾ä¸‹ä¸€ä¸ªç©ºä½
            while ep_num in used_ids:
                ep_num += 1
            used_ids.add(ep_num)
            ep_id = f"episode_{ep_num:03d}"
            # åœ¨è¾“å‡ºé›†åˆæ ¹ä¸‹åˆ›å»ºè¯¥ episode ç›®å½•ï¼Œå¹¶å†™å…¥å ä½ï¼Œä¾› _run_single_episode ä½¿ç”¨
            ep_out_dir = os.path.join(output_root, ep_id)
            os.makedirs(ep_out_dir, exist_ok=True)
            # å°†è¯¥ episode çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„è®°å½•åˆ°ä¸€ä¸ªä¸´æ—¶æ ‡è®°æ–‡ä»¶ï¼Œä¾›å•é›†å¤„ç†è¯»å–
            with open(os.path.join(ep_out_dir, "_local_mp4_path.txt"), 'w', encoding='utf-8') as f:
                f.write(p)
            episodes.append(ep_id)

        print(f"å¼€å§‹Step0: ä¸Šä¼  {len(episodes)} ä¸ªå‰§é›†åˆ°GCS -> {output_root} ...")

        # ä¿®æ”¹é…ç½®çš„ project_root æŒ‡å‘è¾“å‡ºé›†åˆæ ¹ï¼Œä»¥å¤ç”¨ _run_single_episode é€»è¾‘
        # å¹¶è®© _run_single_episode è¯»å– _local_mp4_path.txt ä½œä¸ºä¸Šä¼ æº
        results = []
        # å°†é›†åˆåä¼ é€’ç»™å­è°ƒç”¨
        os.environ['STEP0_OUT_COLLECTION'] = collection_name
        max_workers = self.config.get_step_config(0).get('max_workers', 2)  # é™ä½å¹¶å‘æ•°ï¼Œå‡å°‘ç½‘ç»œå‹åŠ›
        # ç¬¬ä¸€è½®ä¸Šä¼ 
        print("ğŸš€ å¼€å§‹ç¬¬ä¸€è½®ä¸Šä¼ ...")
        results = self._upload_episodes_batch(episodes, max_workers)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = len([r for r in results if r.get("status") == "success"])
        already_exists_count = len([r for r in results if r.get("status") == "already_exists"])
        failed_episodes = [r for r in results if r.get("status") in ["failed", "upload_failed", "no_mp4_found"]]
        failed_count = len(failed_episodes)

        print(f"\nç¬¬ä¸€è½®ä¸Šä¼ ç»Ÿè®¡:")
        print(f"- æˆåŠŸä¸Šä¼ : {success_count}")
        print(f"- å·²å­˜åœ¨: {already_exists_count}")
        print(f"- å¤±è´¥: {failed_count}")

        # å¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œè¿›è¡Œé‡è¯•
        if failed_episodes:
            print(f"\nğŸ”„ å¼€å§‹é‡è¯•å¤±è´¥çš„ {len(failed_episodes)} ä¸ªæ–‡ä»¶...")
            failed_episode_ids = [r.get("episode_id") for r in failed_episodes if r.get("episode_id")]
            
            # é‡è¯•å¤±è´¥çš„æ–‡ä»¶
            retry_results = self._upload_episodes_batch(failed_episode_ids, max_workers)
            
            # æ›´æ–°ç»“æœ
            for retry_result in retry_results:
                episode_id = retry_result.get("episode_id")
                if episode_id:
                    # æ‰¾åˆ°åŸæ¥çš„ç»“æœå¹¶æ›´æ–°
                    for i, original_result in enumerate(results):
                        if original_result.get("episode_id") == episode_id:
                            results[i] = retry_result
                            break
            
            # é‡æ–°ç»Ÿè®¡
            success_count = len([r for r in results if r.get("status") == "success"])
            already_exists_count = len([r for r in results if r.get("status") == "already_exists"])
            final_failed_count = len([r for r in results if r.get("status") in ["failed", "upload_failed", "no_mp4_found"]])
            
            print(f"\né‡è¯•åæœ€ç»ˆç»Ÿè®¡:")
            print(f"- æˆåŠŸä¸Šä¼ : {success_count}")
            print(f"- å·²å­˜åœ¨: {already_exists_count}")
            print(f"- å¤±è´¥: {final_failed_count}")
        else:
            print("âœ… æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ— éœ€é‡è¯•")

        return {
            "status": "completed",
            "total_episodes": len(episodes),
            "success_count": success_count,
            "already_exists_count": already_exists_count,
            "failed_count": len([r for r in results if r.get("status") in ["failed", "upload_failed", "no_mp4_found"]]),
            "results": results
        }
    
    def _upload_episodes_batch(self, episodes: List[str], max_workers: int) -> List[Dict[str, Any]]:
        """æ‰¹é‡ä¸Šä¼ å‰§é›†"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        from tqdm import tqdm
        
        results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self._run_single_episode, ep): ep for ep in episodes}
            for future in tqdm(as_completed(futures), total=len(episodes), desc="Step0"):
                episode_id = futures[future]
                try:
                    result = future.result()
                    result["episode_id"] = episode_id  # ç¡®ä¿åŒ…å«episode_id
                    results.append(result)
                except Exception as e:
                    print(f"Step0 å¤„ç† {episode_id} å¤±è´¥: {e}")
                    results.append({"episode_id": episode_id, "status": "failed", "error": str(e)})
        return results
    
    def _upload_to_gcs(self, local_file: str, episode_id: str, file_name: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°GCS"""
        import requests
        from google.cloud.storage import transfer_manager
        
        # åˆå§‹åŒ–GCSå®¢æˆ·ç«¯ï¼Œè®¾ç½®è¶…æ—¶
        gcp_config = self.config.gcp_config
        client = storage.Client.from_service_account_json(gcp_config['credentials_path'])
        
        # æ„å»ºGCSè·¯å¾„
        bucket_name = os.environ.get('STEP0_BUCKET_NAME', gcp_config.get('bucket_name', 'script-generation-videos'))
        # è‹¥è®¾ç½®äº†é›†åˆåï¼Œåˆ™æŒ‰é›†åˆåå½’æ¡£ï¼›ä¸å†ä½¿ç”¨ episode å­è·¯å¾„
        collection = os.environ.get('STEP0_COLLECTION')
        if collection:
            gcs_key = f"{collection}/{file_name}"
            gcs_path = f"gs://{bucket_name}/{collection}/{file_name}"
        else:
            gcs_key = file_name
            gcs_path = f"gs://{bucket_name}/{file_name}"
        
        try:
            # æ£€æŸ¥bucketæ˜¯å¦å­˜åœ¨
            bucket = client.bucket(bucket_name)
            bucket.reload()  # éªŒè¯bucketå­˜åœ¨
        except NotFound:
            print(f"âš ï¸  Bucket {bucket_name} ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...")
            try:
                bucket = client.create_bucket(bucket_name, location=gcp_config['location'])
                print(f"âœ… æˆåŠŸåˆ›å»ºbucket: {bucket_name}")
            except Exception as e:
                print(f"âŒ æ— æ³•åˆ›å»ºbucket: {e}")
                # ä½¿ç”¨é»˜è®¤bucket
                bucket_name = f"{gcp_config['project_id']}-script-videos"
                bucket = client.bucket(bucket_name)
                gcs_path = f"gs://{bucket_name}/{file_name}"
                print(f"ğŸ”„ ä½¿ç”¨é»˜è®¤bucket: {bucket_name}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        blob = bucket.blob(gcs_key)
        
        if blob.exists():
            print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨äºGCS: {gcs_path}")
            return gcs_path
        
        # è·å–æ–‡ä»¶å¤§å°ï¼Œè®¾ç½®åˆé€‚çš„è¶…æ—¶æ—¶é—´
        file_size = os.path.getsize(local_file)
        file_size_mb = file_size / (1024 * 1024)
        
        # æ ¹æ®æ–‡ä»¶å¤§å°è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆæ¯MB 10ç§’ï¼Œæœ€å°‘60ç§’ï¼Œæœ€å¤š600ç§’ï¼‰
        timeout_seconds = max(60, min(600, int(file_size_mb * 10)))
        
        print(f"ğŸ“¤ ä¸Šä¼  {local_file} ({file_size_mb:.1f}MB) åˆ° {gcs_path} (è¶…æ—¶: {timeout_seconds}ç§’)")
        
        # ä½¿ç”¨ä¼˜åŒ–çš„ä¸Šä¼ è®¾ç½®
        try:
            # è®¾ç½®é‡è¯•ç­–ç•¥
            retry_strategy = storage.retry.DEFAULT_RETRY.with_deadline(timeout_seconds)
            
            # å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            if file_size > 50 * 1024 * 1024:  # 50MB
                print(f"ğŸ”„ ä¸Šä¼ å¤§æ–‡ä»¶ (æ–‡ä»¶å¤§å°: {file_size_mb:.1f}MB)")
                # å¤§æ–‡ä»¶ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                extended_timeout = max(timeout_seconds, 300)  # è‡³å°‘5åˆ†é’Ÿ
                blob.upload_from_filename(
                    local_file,
                    timeout=extended_timeout,
                    retry=retry_strategy
                )
            else:
                # å°æ–‡ä»¶ç›´æ¥ä¸Šä¼ 
                blob.upload_from_filename(
                    local_file,
                    timeout=timeout_seconds,
                    retry=retry_strategy
                )
        except Exception as e:
            # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œå°è¯•æ›´ç®€å•çš„è®¾ç½®
            print(f"âš ï¸ æ ‡å‡†ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•ç®€åŒ–ä¸Šä¼ : {e}")
            try:
                blob.upload_from_filename(local_file)
            except Exception as e2:
                print(f"âŒ ç®€åŒ–ä¸Šä¼ ä¹Ÿå¤±è´¥: {e2}")
                raise e2
        
        return gcs_path


