"""
Step0.2: åˆ†é›†è§’è‰²ä¸å…³ç³»çº¿ç´¢æå–
ä»æ¯ä¸€é›†çš„è§†é¢‘å’Œå¯¹è¯æ–‡æœ¬ä¸­æå–è§’è‰²çº¿ç´¢å’Œå…³ç³»ä¿¡æ¯
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from . import PipelineStep
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from typing import Dict, List, Any
import json


class Step0_2ClueExtraction(PipelineStep):
    """åˆ†é›†è§’è‰²ä¸å…³ç³»çº¿ç´¢æå–æ­¥éª¤"""
    
    def __init__(self, config):
        super().__init__(config)
        self._step_name = "Step0.2"
        self._description = "åˆ†é›†è§’è‰²ä¸å…³ç³»çº¿ç´¢æå–"
        # å…ˆéªŒæ–‡ä»¶è·¯å¾„ï¼ˆä¸²è¡Œæ—¶ç”¨äºè·¨é›†ä¼ é€’ï¼‰
        self.prior_file = os.path.join(self.config.project_root, "0_2_prior.json")
    
    @property
    def step_number(self) -> int:
        """æ­¥éª¤ç¼–å·"""
        return 0.2
    
    @property
    def step_name(self) -> str:
        """æ­¥éª¤åç§°"""
        return self._step_name
    
    def run(self) -> Dict[str, Any]:
        """è¿è¡Œçº¿ç´¢æå–"""
        return self._run_all_episodes()
    
    def _run_all_episodes(self) -> Dict[str, Any]:
        """å¤„ç†æ‰€æœ‰å‰§é›†ï¼ˆä¸²è¡Œ + å…ˆéªŒæ³¨å…¥/åˆå¹¶ï¼‰"""
        episodes = self.utils.get_episode_list(self.config.project_root)
        episodes = sorted(episodes)
        results = []
        print(f"å¼€å§‹{self.step_name}: ä¸²è¡Œå¤„ç† {len(episodes)} ä¸ªå‰§é›†...")

        # ç¡®ä¿å…ˆéªŒæ–‡ä»¶å­˜åœ¨
        prior = self._load_prior()

        for episode_id in tqdm(episodes, total=len(episodes), desc=self.step_name):
            try:
                result = self._run_single_episode(episode_id, prior)
                result["episode_id"] = episode_id
                results.append(result)
                # å°†æœ¬é›†ä¿¡æ¯åˆå¹¶å…¥å…ˆéªŒå¹¶ä¿å­˜
                self._merge_prior(prior, episode_id)
                self._save_prior(prior)
            except Exception as e:
                print(f"âŒ {self.step_name} å¤„ç† {episode_id} å¤±è´¥: {e}")
                results.append({
                    "episode_id": episode_id, 
                    "status": "failed", 
                    "error": str(e)
                })

        stats = self._generate_statistics(results)
        print(f"\nğŸ“Š {self.step_name} å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"   æ€»å‰§é›†æ•°: {stats['total_episodes']}")
        print(f"   æˆåŠŸå¤„ç†: {stats['success_count']}")
        print(f"   å¤±è´¥å¤„ç†: {stats['failed_count']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")

        return {
            "status": "completed", 
            "results": results,
            "statistics": stats
        }
    
    def _run_single_episode(self, episode_id: str, prior: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªå‰§é›†ï¼ˆåœ¨æ„å»ºpromptæ—¶æ³¨å…¥å…ˆéªŒï¼‰"""
        print(f"{self.step_name}: å¤„ç† {episode_id}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶
        output_file = f"{self.config.project_root}/{episode_id}/0_2_clues.json"
        if os.path.exists(output_file) and not os.getenv('FORCE_OVERWRITE'):
            print(f"âœ… {episode_id} å·²æœ‰{self.step_name}è¾“å‡ºæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
            return {"status": "already_exists"}
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶ï¼ˆä¼˜å…ˆSRTï¼Œå…¼å®¹æ—§ç‰ˆTXTï¼‰
        asr_srt = f"{self.config.project_root}/{episode_id}/0_1_timed_dialogue.srt"
        asr_txt = f"{self.config.project_root}/{episode_id}/0_1_timed_dialogue.txt"
        asr_file = asr_srt if os.path.exists(asr_srt) else (asr_txt if os.path.exists(asr_txt) else None)
        if not asr_file:
            print(f"âŒ {episode_id} ç¼ºå°‘ASRè¾“å…¥æ–‡ä»¶: {asr_srt} æˆ– {asr_txt}")
            return {"status": "failed", "error": "ç¼ºå°‘ASRè¾“å…¥æ–‡ä»¶"}
        
        # è·å–è§†é¢‘URI
        video_uri = self.utils.get_video_uri(episode_id, self.config.project_root)
        
        # è¯»å–ASRå¯¹è¯å†…å®¹
        with open(asr_file, 'r', encoding='utf-8') as f:
            asr_content = f.read()
        
        # ä½¿ç”¨æ¨¡å‹é…ç½®
        model_config = self.config.get_model_config_by_name("step0_2")  # ä½¿ç”¨step0_2é…ç½®
        
        # æ€è€ƒé¢„ç®—é…ç½®ï¼ˆ0è¡¨ç¤ºè·³è¿‡æ€è€ƒï¼Œæå‡é€Ÿåº¦ï¼‰
        thinking_budget = model_config.get("thinking_budget", 0)
        print(f"ğŸ§  æ€è€ƒé¢„ç®—é…ç½®: {thinking_budget} (0=è·³è¿‡æ€è€ƒï¼Œæå‡é€Ÿåº¦)")
        
        # æ„å»ºprompt
        system_instruction = """ä½ æ˜¯å½±è§†å‰§åˆ†æçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨æ‰§è¡Œå¤§è§„æ¨¡åˆ†æä»»åŠ¡çš„ç¬¬ä¸€æ­¥ã€‚

ä½ çš„å”¯ä¸€ä»»åŠ¡ï¼šåªè®°å½•ä½ çœ‹åˆ°å’Œå¬åˆ°çš„â€œåŸå§‹çº¿ç´¢â€ï¼Œé¿å…è¿›è¡Œä»»ä½•æ¨æ–­æˆ–ä¸‹ç»“è®ºã€‚ä¸¥æ ¼æŒ‰JSONç»“æ„è¾“å‡ºï¼Œä¸è¦æ·»åŠ è§£é‡Šã€‚

æ ¸å¿ƒä»»åŠ¡ï¼š
1. æ˜¾å¼è§’è‰²è¯†åˆ« (Explicit Characters) â€” ä»…åŸºäºå¯æ ¸éªŒå‘½åä¿¡å·
   - ä»…æ”¶å½•ä¸¤ç±»æ¥æºï¼š
     a) onscreen_nameï¼ˆäººåæ¡/è§’è‰²å¡ï¼‰ï¼šå¿…é¡»è¾“å‡º nameã€title_or_roleã€appearance_method=onscreen_nameã€evidence_modality=onscreen_cardã€evidence_quoteï¼ˆå¡é¢æ–‡å­—ï¼‰
     b) explicit_dialogueï¼ˆæ˜ç¡®å…¨åå‘¼å”¤ï¼Œéç§°è°“/éä»å±ï¼‰ï¼šappearance_method=explicit_dialogueï¼Œé™„ evidence_modality=subtitle|voice ä¸ evidence_quote
   - ç¦æ­¢å°†ä»¥ä¸‹æ¥æºè½åœ°ä¸ºæ˜¾å¼è§’è‰²ï¼švisual_inference / prior / honorificï¼ˆå°å§/æ€»/å¤«äºº/åŒ»ç”Ÿâ€¦ï¼‰/â€œXçš„åŠ©ç†/å¸æœº/ä¿é•–/ä¸‹å±/éšä»â€ç­‰åŠŸèƒ½/ä»å±ç§°è°“
   - å®ˆé—¨è§„åˆ™ï¼šè‹¥ name åŒ¹é…â€œ.+çš„(åŠ©ç†|å¸æœº|ä¿é•–|ä¸‹å±|éšä»)$â€ï¼Œæˆ–ä»…å‡­è§†è§‰/ç§°è°“/åŒæ¡†å¾—åˆ°çš„å‘½åï¼Œä¸€å¾‹ä¸è¦è¿›å…¥ explicit_charactersï¼›æ”¹åœ¨ observed_interactions æˆ– speaker_profiles è®°å½•è¯æ®

2. åŒ¿åè¯´è¯äººæ¡£æ¡ˆ (Speaker Profiles)
   - æŒ‰ spk_X å»ºæ¡£ï¼švisualï¼ˆå¤–è§‚ï¼‰ã€voiceï¼ˆéŸ³è‰²/å£°çº¹ï¼‰ã€speaking_styleï¼ˆå¯é€‰ï¼‰ã€key_linesï¼ˆ1â€“2å¥ä»£è¡¨å°è¯ï¼‰
   - honorific å¯è®°å½•åœ¨ key_lines ä¸­ï¼Œä½†ä¸å¾—ç”¨äºæ”¹å†™å§“åæˆ–ç”Ÿæˆä»å±å‘½å

3. è§‚å¯Ÿåˆ°çš„äº’åŠ¨ (Observed Interactions) â€” åªè®°å½•è¯æ®ï¼Œä¸åšæ¨æ–­
   - participants: [å‘è¨€è€…spk/è§’è‰², å¯¹è±¡ï¼ˆå¦‚æœ‰ï¼‰]
   - summary: å®¢è§‚æè¿°ï¼ˆä¾‹å¦‚ï¼šspk_2 å¯¹ spk_1 è¯´è¯ï¼ˆaddressï¼‰ï¼›spk_3 æåŠâ€œé™†æ€»â€ï¼ˆmentionï¼‰ï¼‰
   - evidence: å…³é”®å°è¯/å¡é¢æ–‡æœ¬
   - action_type: address | mentionï¼ˆåŒºåˆ†æ­£åœ¨å¯¹è°è¯´ vs æåŠç¬¬ä¸‰äººï¼‰
   - addressee: è‹¥ addressï¼Œå†™è§„èŒƒå/spk_ID/second_personï¼›å¦åˆ™ç•™ç©º
   - referents: è‹¥ mentionï¼Œå†™è¢«æåŠå¯¹è±¡æ•°ç»„ï¼›å¦åˆ™ä¸ºç©º
   - speech_act: report | command | question | inform
   - observation_type: vocal | subtitle | onscreen_card | visual_context
   - certainty_level: high | medium | lowï¼ˆçŸ­ç¡®è®¤/ç¤¼è²Œæ€§å½’ lowï¼‰
   - start_ms/end_msã€evidence_span

å‘½åä¸åˆå¹¶è§„åˆ™ï¼ˆå¼ºä¸€è‡´ï¼‰ï¼š
- å‘½åä¼˜å…ˆçº§ï¼šäººåæ¡/å¡ï¼ˆonscreen_nameï¼‰ > æ˜ç¡®å…¨åå‘¼å”¤ï¼ˆexplicit_dialogueï¼‰ï¼Œç¦æ­¢è‡†é€ ä¸­æ–‡å…¨å
- honorific/ç§°è°“ä¸è§†è§‰/å…ˆéªŒä»…ä½œä¸ºè¯æ®ï¼Œä¸å¾—æ”¹åæˆ–ç”Ÿæˆâ€œXçš„åŠ©ç†/å¸æœº/ä¿é•–/ä¸‹å±/éšä»â€ç­‰å‘½å
- è‹¥å½“é›†äººåæ¡/å­—å¹•ä¸å…ˆéªŒå†²çªï¼Œä»¥å½“é›†ä¸ºå‡†ï¼›å…ˆéªŒä»…ä½œåˆ«åæˆ–è¯æ®å‚è€ƒ
- æ¢è£…/å½¢è±¡å˜åŒ–å†™å…¥ traitsï¼Œä¿æŒåŒä¸€è§„èŒƒå

è¾“å‡ºè¦æ±‚ï¼š
- ä»…è¾“å‡º explicit_charactersã€speaker_profilesã€observed_interactions ä¸‰ä¸ªéƒ¨åˆ†
- ä¸è¾“å‡º name_alignment_hintsï¼Œä¸è¾“å‡ºä»å±/é…å¶ç­‰å…³ç³»ç»“è®º
- è¯æ®å­—æ®µé½å…¨ï¼ˆmodality/quote/action_type/speech_act/certainty ç­‰ï¼‰"""

        prior_text = self._render_prior_text(prior)

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹è§†é¢‘å’Œå¯¹è¯å†…å®¹ï¼Œæå–è§’è‰²çº¿ç´¢å’Œå…³ç³»ä¿¡æ¯ï¼š

ã€å·²çŸ¥è§’è‰²å…ˆéªŒï¼ˆæœ€é«˜ä¼˜å…ˆï¼‰ã€‘
{prior_text}

ASRå¯¹è¯å†…å®¹ï¼š
{asr_content}

è¯·æŒ‰ç…§è¦æ±‚æå–ï¼š
1. æ˜¾å¼è§’è‰²åˆ—è¡¨
2. æ¯ä¸ªspk_Xçš„è¯¦ç»†æ¡£æ¡ˆ
3. æ‰€æœ‰å…³ç³»çº¿ç´¢ä¸‰å…ƒç»„

æ³¨æ„ï¼šä»”ç»†è§‚çœ‹è§†é¢‘ä¸­çš„è§†è§‰ä¿¡æ¯ï¼Œç»“åˆå¯¹è¯å†…å®¹è¿›è¡Œç»¼åˆåˆ†æã€‚"""

        # å®šä¹‰JSON schema
        schema = {
            "type": "object",
            "properties": {
                "episode_id": {"type": "string"},
                "explicit_characters": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "appearance_method": {"type": "string", "enum": ["onscreen_name", "explicit_dialogue", "prior", "visual_inference"]},
                            "confidence": {"type": "number"},
                            "traits": {"type": "string"},
                            "title_or_role": {"type": "string"},
                            "evidence_quote": {"type": "string"},
                            "evidence_modality": {"type": "string", "enum": ["subtitle", "voice", "onscreen_card"]}
                        },
                        "required": ["name", "appearance_method", "confidence", "traits", "evidence_quote", "evidence_modality"]
                    }
                },
                "speaker_profiles": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "visual_description": {"type": "string"},
                            "key_lines": {
                                "type": "array",
                                "items": {"type": "string"}
                            },
                            "emotional_tone": {"type": "string"},
                            "speaking_style": {"type": "string"}
                        },
                        "required": ["id", "visual_description", "key_lines", "emotional_tone", "speaking_style"]
                    }
                },
                "observed_interactions": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "participants": {"type": "array", "items": {"type": "string"}},
                            "summary": {"type": "string"},
                            "evidence": {"type": "string"},
                            "action_type": {"type": "string", "enum": ["address", "mention"]},
                            "addressee": {"type": "string"},
                            "referents": {"type": "array", "items": {"type": "string"}},
                            "speech_act": {"type": "string", "enum": ["report", "command", "question", "inform"]},
                            "observation_type": {"type": "string", "enum": ["vocal", "subtitle", "onscreen_card", "visual_context"]},
                            "certainty_level": {"type": "string", "enum": ["high", "medium", "low"]},
                            "evidence_span": {"type": "string"},
                            "start_ms": {"type": "integer"},
                            "end_ms": {"type": "integer"}
                        },
                        "required": ["participants", "summary", "evidence", "action_type"]
                    }
                }
            },
            "required": ["episode_id", "explicit_characters", "speaker_profiles", "observed_interactions"]
        }
        
        # é‡è¯•æœºåˆ¶
        max_retries = 3
        retry_delay = 2
        
        # å®šä¹‰æ¨¡å‹åˆ—è¡¨ï¼Œç”¨äºé‡è¯•æ—¶åˆ‡æ¢
        model_list = [
            'gemini-2.5-flash',  # ä¸»è¦æ¨¡å‹
            'gemini-2.0-flash',  # å¤‡ç”¨æ¨¡å‹1
            'gemini-2.5-pro'     # å¤‡ç”¨æ¨¡å‹2
        ]
        
        for attempt in range(max_retries + 2):  # å¢åŠ 2æ¬¡æ¨¡å‹åˆ‡æ¢é‡è¯•
            try:
                # é€‰æ‹©æ¨¡å‹ï¼šå‰3æ¬¡ä½¿ç”¨ä¸»æ¨¡å‹ï¼Œå2æ¬¡åˆ‡æ¢å¤‡ç”¨æ¨¡å‹
                if attempt < max_retries:
                    model_name = model_list[0]  # ä½¿ç”¨ä¸»æ¨¡å‹
                else:
                    model_name = model_list[attempt - max_retries + 1]  # åˆ‡æ¢å¤‡ç”¨æ¨¡å‹
                    print(f"ğŸ”„ ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œåˆ‡æ¢æ¨¡å‹: {model_name}")
                
                if attempt > 0:
                    print(f"ğŸ”„ ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
                    import time
                    time.sleep(retry_delay * min(attempt, 3))  # æœ€å¤§å»¶è¿Ÿ6ç§’
                
                result = self.client.generate_content(
                    model=model_name,
                    prompt=user_prompt,
                    video_uri=video_uri,
                    max_tokens=model_config.get("max_tokens", 65535),
                    temperature=model_config.get("temperature", 0.1),
                    system_instruction=system_instruction,
                    schema=schema,
                    thinking_budget=thinking_budget
                )
                
                # è§£æç»“æœ
                if isinstance(result, dict) and result.get("episode_id"):
                    print(f"âœ… ç¬¬{attempt+1}æ¬¡è°ƒç”¨æˆåŠŸï¼Œæå–åˆ°çº¿ç´¢")
                    break
                else:
                    print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡è°ƒç”¨æˆåŠŸä½†è§£æå¤±è´¥ï¼Œmodel={model_name}")
                    print(f"è¿”å›ç»“æœ: {result}")
                    if attempt < max_retries + 1:  # å…è®¸æ›´å¤šé‡è¯•
                        print(f"ğŸ”„ é‡è¯•ä¸­...")
            except Exception as e:
                error_type = type(e).__name__
                print(f"âŒ ç¬¬{attempt+1}æ¬¡è°ƒç”¨å¼‚å¸¸ ({error_type}): {e}")
                if attempt < max_retries + 1:  # å…è®¸æ›´å¤šé‡è¯•
                    print(f"ğŸ”„ é‡è¯•ä¸­...")
                else:
                    print(f"âŒ {episode_id} {self.step_name} æœ€ç»ˆå¤±è´¥: {error_type} - {e}")
                    result = {"episode_id": episode_id, "explicit_characters": [], "speaker_profiles": [], "relationship_clues": []}
        
        # ç¡®ä¿episode_idæ­£ç¡®
        if isinstance(result, dict):
            result["episode_id"] = episode_id
        
        # ä¿å­˜ç»“æœ
        self.utils.save_json_file(output_file, result, ensure_ascii=False)
        print(f"âœ… {episode_id} {self.step_name} å®Œæˆ")
        
        return {
            "status": "success",
            "explicit_characters_count": len(result.get("explicit_characters", [])),
            "speaker_profiles_count": len(result.get("speaker_profiles", [])),
            "observed_interactions_count": len(result.get("observed_interactions", []))
        }

    def _load_prior(self) -> Dict[str, Any]:
        """åŠ è½½å…ˆéªŒæ–‡ä»¶ï¼Œä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤ç»“æ„"""
        if os.path.exists(self.prior_file):
            try:
                with open(self.prior_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å…ˆéªŒå¤±è´¥ï¼Œå°†ä½¿ç”¨ç©ºå…ˆéªŒ: {e}")
        return {
            "version": 1,
            "updated_at": "",
            "characters": [],
            "name_variants": {}
        }

    def _save_prior(self, prior: Dict[str, Any]):
        """ä¿å­˜å…ˆéªŒæ–‡ä»¶"""
        try:
            from datetime import datetime
            prior["updated_at"] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
            self.utils.save_json_file(self.prior_file, prior, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å…ˆéªŒå¤±è´¥: {e}")

    def _render_prior_text(self, prior: Dict[str, Any]) -> str:
        """å°†å…ˆéªŒæ¸²æŸ“ä¸ºçŸ­æ–‡æœ¬æ³¨å…¥Prompt"""
        if not prior or not prior.get("characters"):
            return "(æ— )"
        lines = []
        # è§’è‰²æ‘˜è¦ï¼ˆé™åˆ¶å‰è‹¥å¹²ï¼Œé¿å…tokenè¿‡å¤§ï¼‰
        for ch in prior.get("characters", [])[:30]:
            name = ch.get("canonical_name", "")
            traits = ch.get("traits_brief", "")
            aliases = ch.get("aliases", [])
            alias_text = f"ï¼›å¸¸è§åˆ«ç§°ï¼š{'/'.join(aliases)}" if aliases else ""
            lines.append(f"- {name}ï¼š{traits}{alias_text}")
        # å˜ä½“å½’ä¸€
        variants = prior.get("name_variants", {})
        if variants:
            pair_lines = [f"{k}â†’{v}" for k, v in list(variants.items())[:50]]
            lines.append("å˜ä½“å½’ä¸€ï¼š" + "ï¼›".join(pair_lines))
        return "\n".join(lines)

    def _merge_prior(self, prior: Dict[str, Any], episode_id: str):
        """å°†æœ¬é›† explicit_characters åˆå¹¶è¿›å…ˆéªŒ"""
        # è¯»å–æœ¬é›†è¾“å‡º
        file_path = os.path.join(self.config.project_root, episode_id, "0_2_clues.json")
        if not os.path.exists(file_path):
            return
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¯»å–æœ¬é›†çº¿ç´¢å¤±è´¥ï¼Œè·³è¿‡å…ˆéªŒåˆå¹¶: {e}")
            return

        characters = prior.setdefault("characters", [])
        name_variants = prior.setdefault("name_variants", {})

        # ç®€å•çš„åç§°åˆ°ç´¢å¼•æ˜ å°„
        name_to_idx = {c.get("canonical_name", ""): idx for idx, c in enumerate(characters)}

        for ec in data.get("explicit_characters", []):
            name = (ec.get("name") or "").strip()
            if not name:
                continue
            traits = (ec.get("traits") or "").strip()
            confidence = float(ec.get("confidence", 0.6) or 0.6)

            if name in name_to_idx:
                idx = name_to_idx[name]
                ch = characters[idx]
                # åˆå¹¶ traits_briefï¼ˆä»¥è¾ƒçŸ­æ‘˜è¦ä¸ºä¸»ï¼Œé¿å…æ— ä¸Šé™å¢é•¿ï¼‰
                old_traits = ch.get("traits_brief", "")
                if traits and traits not in old_traits:
                    ch["traits_brief"] = (old_traits + "; " + traits).strip("; ") if old_traits else traits
                # æ›´æ–°è¯æ®ä¸ç½®ä¿¡åº¦ï¼ˆç®€å•å¹³å‡ï¼‰
                ch["evidence_count"] = int(ch.get("evidence_count", 0)) + 1
                old_conf = float(ch.get("confidence", confidence) or confidence)
                ch["confidence"] = round((old_conf + confidence) / 2, 4)
                # è¿½åŠ æ¥æº
                sources = set(ch.get("sources", []))
                sources.add(episode_id)
                ch["sources"] = sorted(list(sources))
            else:
                characters.append({
                    "canonical_name": name,
                    "aliases": [],
                    "traits_brief": traits,
                    "evidence_count": 1,
                    "confidence": round(confidence, 4),
                    "sources": [episode_id]
                })
                name_to_idx[name] = len(characters) - 1

        # æ³¨ï¼šå¦‚éœ€ç»´æŠ¤å˜ä½“å½’ä¸€ï¼Œå¯åœ¨æ­¤æ ¹æ®å½“é›†æç¤ºæ·»åŠ æ˜ å°„ï¼ˆå½“å‰æœ€å°å®ç°ä¸è‡ªåŠ¨æ–°å¢ï¼‰
    
    def _generate_statistics(self, results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        total_episodes = len(results)
        success_count = len([r for r in results if r.get("status") == "success"])
        failed_count = len([r for r in results if r.get("status") == "failed"])
        already_exists_count = len([r for r in results if r.get("status") == "already_exists"])
        
        total_explicit_characters = sum(r.get("explicit_characters_count", 0) for r in results)
        total_speaker_profiles = sum(r.get("speaker_profiles_count", 0) for r in results)
        total_observed_interactions = sum(r.get("observed_interactions_count", 0) for r in results)
        
        return {
            "total_episodes": total_episodes,
            "success_count": success_count,
            "failed_count": failed_count,
            "already_exists_count": already_exists_count,
            "success_rate": (success_count / total_episodes * 100) if total_episodes > 0 else 0,
            "total_explicit_characters": total_explicit_characters,
            "total_speaker_profiles": total_speaker_profiles,
            "total_observed_interactions": total_observed_interactions,
            "avg_explicit_characters": total_explicit_characters / success_count if success_count > 0 else 0,
            "avg_speaker_profiles": total_speaker_profiles / success_count if success_count > 0 else 0,
            "avg_observed_interactions": total_observed_interactions / success_count if success_count > 0 else 0
        }


if __name__ == "__main__":
    from new_pipeline.core import PipelineConfig
    config = PipelineConfig()
    step = Step0_2ClueExtraction(config)
    result = step.run()
    print(f"æœ€ç»ˆç»“æœ: {result}")
