"""
Step0.4: è¯´è¯äººèº«ä»½æ ¡å‡†
ä½¿ç”¨å…¨å±€äººç‰©å…³ç³»å›¾è°±æ ¡å‡†åŒ¿åè¯´è¯äººIDä¸ºå…·ä½“è§’è‰²å
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from . import PipelineStep
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from typing import Dict, List, Any
import json
import re

from new_pipeline.steps.commont_log import log

class Step0_4SpeakerCalibration(PipelineStep):
    """è¯´è¯äººèº«ä»½æ ¡å‡†æ­¥éª¤"""
    
    def __init__(self, config):
        super().__init__(config)
        self._step_name = "Step0.4"
        self._description = "è¯´è¯äººèº«ä»½æ ¡å‡†"
        self.global_graph = None
    
    @property
    def step_number(self) -> int:
        """æ­¥éª¤ç¼–å·"""
        return 0.4
    
    @property
    def step_name(self) -> str:
        """æ­¥éª¤åç§°"""
        return self._step_name
    
    def run(self) -> Dict[str, Any]:
        """è¿è¡Œè¯´è¯äººèº«ä»½æ ¡å‡†"""
        # åŠ è½½å…¨å±€å›¾è°±ï¼ˆä¼˜å…ˆLLMç‰ˆï¼Œå…¶æ¬¡å¯å‘å¼ç‰ˆï¼‰â€”â€”å…¼å®¹ä¸¤ç§è½ç›˜ä½ç½®ï¼ˆæ ¹ç›®å½• /global å­ç›®å½•ï¼‰
        candidates = [
            f"{self.config.project_root}/global/global_character_graph_llm.json",
            f"{self.config.project_root}/global_character_graph_llm.json",
            f"{self.config.project_root}/global/global_character_graph.json",
            f"{self.config.project_root}/global_character_graph.json",
        ]
        selected = None
        for p in candidates:
            if os.path.exists(p):
                selected = p
                break
        if not selected:
            log.info("âŒ å…¨å±€å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡ŒStep0.3/Step0.3-LLM")
            return {"status": "failed", "error": "å…¨å±€å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨"}
        with open(selected, 'r', encoding='utf-8') as f:
            self.global_graph = json.load(f)
        
        # å…¼å®¹ä¸åŒç»“æ„ï¼šLLMç‰ˆæ—  relationships å­—æ®µæ—¶å®‰å…¨æ‰“å°
        rels = self.global_graph.get('relationships', [])
        log.info(f"âœ… åŠ è½½å…¨å±€å›¾è°±: {len(self.global_graph.get('characters', []))} ä¸ªè§’è‰², {len(rels)} ä¸ªå…³ç³» | æ–‡ä»¶: {os.path.relpath(selected, self.config.project_root)}")
        
        return self._run_all_episodes()
    
    def _run_all_episodes(self) -> Dict[str, Any]:
        """å¤„ç†æ‰€æœ‰å‰§é›†"""
        episodes = self.utils.get_episode_list(self.config.project_root)
        results = []
        log.info(f"å¼€å§‹{self.step_name}: å¤„ç† {len(episodes)} ä¸ªå‰§é›†...")
        
        # å¹¶å‘é…ç½®ï¼šæ­¥éª¤çº§ -> å…¨å±€ -> é»˜è®¤ 2
        step_conf = self.config.get_step_config_by_name('step0_4') or {}
        max_workers = step_conf.get('max_workers')
        if max_workers is None:
            conc_conf = getattr(self.config, 'concurrency', {}) or {}
            max_workers = conc_conf.get('max_workers', 2)
        try:
            max_workers = int(max_workers)
        except Exception:
            max_workers = 2
        if max_workers < 1:
            max_workers = 1
        log.info(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œçº¿ç¨‹å¤„ç†...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_episode = {
                executor.submit(self._run_single_episode, ep): ep 
                for ep in episodes
            }
            
            for future in tqdm(as_completed(future_to_episode), total=len(episodes), desc=self.step_name):
                episode_id = future_to_episode[future]
                try:
                    result = future.result()
                    result["episode_id"] = episode_id
                    results.append(result)
                except Exception as e:
                    log.info(f"âŒ {self.step_name} å¤„ç† {episode_id} å¤±è´¥: {e}")
                    results.append({
                        "episode_id": episode_id, 
                        "status": "failed", 
                        "error": str(e)
                    })
        
        stats = self._generate_statistics(results)
        log.info(f"\nğŸ“Š {self.step_name} å¤„ç†å®Œæˆç»Ÿè®¡:")
        log.info(f"   æ€»å‰§é›†æ•°: {stats['total_episodes']}")
        log.info(f"   æˆåŠŸå¤„ç†: {stats['success_count']}")
        log.info(f"   å¤±è´¥å¤„ç†: {stats['failed_count']}")
        log.info(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        log.info(f"   æ€»æ ¡å‡†å¯¹è¯æ•°: {stats['total_calibrated_dialogues']}")
        
        return {
            "status": "completed", 
            "results": results,
            "statistics": stats
        }
    
    def _run_single_episode(self, episode_id: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªå‰§é›†"""
        log.info(f"{self.step_name}: å¤„ç† {episode_id}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶
        output_file = f"{self.config.project_root}/{episode_id}/0_4_calibrated_dialogue.txt"
        if os.path.exists(output_file) and not os.getenv('FORCE_OVERWRITE'):
            log.info(f"âœ… {episode_id} å·²æœ‰{self.step_name}è¾“å‡ºæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
            return {"status": "already_exists"}
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        # ä¼˜å…ˆä½¿ç”¨ .srt æ–‡ä»¶ï¼Œå›é€€åˆ° .txt æ–‡ä»¶
        asr_file = f"{self.config.project_root}/{episode_id}/0_1_timed_dialogue.srt"
        if not os.path.exists(asr_file):
            asr_file = f"{self.config.project_root}/{episode_id}/0_1_timed_dialogue.txt"
        if not os.path.exists(asr_file):
            log.info(f"âŒ {episode_id} ç¼ºå°‘ASRè¾“å…¥æ–‡ä»¶: {asr_file}")
            return {"status": "failed", "error": "ç¼ºå°‘ASRè¾“å…¥æ–‡ä»¶"}
        
        # è·å–è§†é¢‘URI
        video_uri = self.utils.get_video_uri(episode_id, self.config.project_root)
        
        # è¯»å–ASRå¯¹è¯å†…å®¹
        with open(asr_file, 'r', encoding='utf-8') as f:
            asr_content = f.read()
        
        # ä½¿ç”¨æ¨¡å‹é…ç½®
        model_config = self.config.get_model_config_by_name("step0_4")  # ä½¿ç”¨step0_4é…ç½®
        
        # 3a: çº¯ä»£ç åˆæ­¥å›å¡«ï¼ˆä¸è°ƒç”¨LLMï¼‰
        # æ„å»ºå½“é›† spk åˆå§‹å€™é€‰æ˜ å°„ï¼ˆæ¥è‡ª Step0.3-LLM hintsï¼‰
        initial_map = self._build_initial_assignment(episode_id)
        # è§£æåŸå§‹åˆ†å¥ä¸ºç»“æ„åŒ–
        original_segments = self._parse_srt_like(asr_content)
        # å…ˆè¿›è¡Œ"å›å¡«"ï¼šç”¨å½“é›† initial_map å°† [spk_X] æ˜ å°„ä¸ºè§’è‰²åï¼Œå¾—å‡ºé¢„å¡«çš„ segments
        prefilled_segments = []
        for seg in original_segments:
            orig_speaker = seg.get('speaker','').strip()
            spk_id = orig_speaker[1:-1] if orig_speaker.startswith('[') and orig_speaker.endswith(']') else orig_speaker
            # è®¡ç®—å½“é›†ç¼–å·å˜é‡ï¼ˆæ”¯æŒ spk_X_epN å˜ä½“ï¼‰
            ep_suffix = None
            try:
                ep_num = int(episode_id.split('_')[-1])
                ep_suffix = f"_ep{ep_num}"
            except Exception:
                ep_suffix = None
            candidates = []
            if spk_id:
                candidates.append(spk_id)
                if ep_suffix:
                    candidates.append(spk_id + ep_suffix)
            if orig_speaker:
                candidates.append(orig_speaker)
                if ep_suffix:
                    candidates.append(orig_speaker + ep_suffix)
            for k in list(candidates):
                if k and not k.startswith('['):
                    candidates.append(f"[{k}]")
            mapped = ''
            for k in candidates:
                if k in initial_map:
                    mapped = initial_map[k]
                    break
            final_speaker = f"[{mapped}]" if mapped else (orig_speaker or "")
            prefilled_segments.append({
                'index': int(seg['index']),
                'start_ms': int(seg['start_ms']),
                'end_ms': int(seg['end_ms']),
                'original_spk': orig_speaker,
                'speaker': final_speaker,
                'text': seg['text']
            })
        draft_text = self._render_dialogues_as_srt_like(prefilled_segments)
        # ä»…åœ¨è°ƒè¯•æ—¶è¾“å‡ºè‰ç¨¿æ–‡ä»¶
        if os.getenv('DEBUG_DRAFT') == '1':
            draft_file = f"{self.config.project_root}/{episode_id}/0_4_dialogue_draft.txt"
            self.utils.save_text_file(draft_file, draft_text)

        # ç›´æ¥è¾“å‡ºå›å¡«ç»“æœï¼ˆä¸è°ƒç”¨LLMï¼‰
        output_file = f"{self.config.project_root}/{episode_id}/0_4_calibrated_dialogue.txt"
        self.utils.save_text_file(output_file, draft_text)
        log.info(f"âœ… {episode_id} {self.step_name} å›å¡«å®Œæˆï¼ˆæ— LLMï¼‰")

        # ç»Ÿè®¡
        calibrated_count = self._count_original_dialogues(draft_text)
        original_count = self._count_original_dialogues(asr_content)
        return {
            "status": "completed",
            "original_dialogues": original_count,
            "calibrated_dialogues": calibrated_count,
            "calibration_rate": calibrated_count / original_count if original_count > 0 else 0
        }
    
    def _build_character_summary(self, episode_id: str = None) -> str:
        """æ„å»ºè§’è‰²ä¿¡æ¯æ‘˜è¦ï¼Œä¼˜å…ˆä½¿ç”¨å½“é›†ç‹¬ç«‹æ–‡ä»¶"""
        summary_lines = []
        
        # 1. ä¼˜å…ˆå°è¯•è¯»å–å½“é›†ç‹¬ç«‹çš„ 0_3_speaker_hints.csv
        if episode_id:
            ep_hints_csv = os.path.join(self.config.project_root, episode_id, '0_3_speaker_hints.csv')
            
            if os.path.exists(ep_hints_csv):
                try:
                    import csv
                    summary_lines.append(f"ã€{episode_id} è§’è‰²ç™½åå•ï¼ˆå½“é›†æ–‡ä»¶ï¼‰ã€‘")
                    
                    with open(ep_hints_csv, 'r', encoding='utf-8') as f:
                        reader = csv.DictReader(f)
                        hints = list(reader)
                    
                    # æŒ‰è§’è‰²ç±»å‹åˆ†ç»„
                    protagonists = []
                    supporting = []
                    for h in hints:
                        role_type = h.get('role_type', '').strip()
                        if role_type == 'protagonist':
                            protagonists.append(h)
                        else:
                            supporting.append(h)
                    
                    # ä¸»è§’åˆ—è¡¨
                    if protagonists:
                        summary_lines.append("ä¸»è§’:")
                        for h in protagonists:
                            cand = h.get('candidate', '')
                            evidence = h.get('evidence', '')
                            conf = h.get('confidence', '')
                            sticky = h.get('sticky', '')
                            summary_lines.append(f"- {cand} (ç½®ä¿¡åº¦:{conf}" + (", é”å®š" if sticky.lower() in ['true', '1', 'yes'] else "") + f"): {evidence}")
                    
                    # é…è§’åˆ—è¡¨
                    if supporting:
                        summary_lines.append("é…è§’:")
                        for h in supporting:
                            cand = h.get('candidate', '')
                            evidence = h.get('evidence', '')
                            owner = h.get('affiliation_owner', '')
                            conf = h.get('confidence', '')
                            sticky = h.get('sticky', '')
                            summary_lines.append(f"- {cand}" + (f" ä»å±äº {owner}" if owner else "") + f" (ç½®ä¿¡åº¦:{conf}" + (", é”å®š" if sticky.lower() in ['true', '1', 'yes'] else "") + f"): {evidence}")
                    
                    # è¯´è¯äººæ˜ å°„
                    summary_lines.append("è¯´è¯äººæ˜ å°„:")
                    for h in hints:
                        spk = h.get('spk_full_id', '')
                        cand = h.get('candidate', '')
                        conf = h.get('confidence', '')
                        evidence = h.get('evidence', '')
                        summary_lines.append(f"- {spk} â†’ {cand} (ç½®ä¿¡åº¦:{conf}): {evidence}")
                    
                    log.info(f"âœ… ä»å½“é›†æ–‡ä»¶æ„å»ºè§’è‰²æ‘˜è¦: {ep_hints_csv}")
                    return "\n".join(summary_lines)
                except Exception as e:
                    log.info(f"âš ï¸ è¯»å–å½“é›†æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        # 2. å›é€€åˆ°å…¨å±€å›¾è°±
        if not self.global_graph:
            return "æ— è§’è‰²ä¿¡æ¯"
        
        per_eps = self.global_graph.get('per_episode') or []
        ep_entry = None
        if episode_id:
            for e in per_eps:
                if e.get('episode_id') == episode_id:
                    ep_entry = e
                    break
        
        if ep_entry:
            summary_lines.append("[æœ¬é›†ä¸»è§’]")
            for p in ep_entry.get('protagonists', []) or []:
                summary_lines.append(f"- {p.get('canonical_name','')} ï½œ {p.get('title_or_role','')} ï½œ {p.get('episode_traits','')}")
            summary_lines.append("[æœ¬é›†é…è§’]")
            for s in ep_entry.get('supporting', []) or []:
                summary_lines.append(f"- {s.get('label','')} ï½œ {s.get('episode_traits','')}")
        else:
            for char in self.global_graph.get("characters", []):
                name = char.get("canonical_name", "")
                traits = char.get("traits", "")
                aliases = char.get("aliases", [])
                summary_lines.append(f"- {name}: {traits}")
                if aliases:
                    summary_lines.append(f"  åˆ«å: {', '.join(aliases)}")
        
        log.info(f"âœ… ä»å…¨å±€å›¾è°±æ„å»ºè§’è‰²æ‘˜è¦")
        return "\n".join(summary_lines)
    
    def _count_calibrated_dialogues(self, content: str) -> int:
        """ç»Ÿè®¡æ ¡å‡†åçš„å¯¹è¯æ•°é‡"""
        # ç»Ÿè®¡åŒ…å«è§’è‰²åç§°çš„å¯¹è¯è¡Œ
        lines = content.split('\n')
        count = 0
        for line in lines:
            if re.match(r'^\d+$', line.strip()):  # å¯¹è¯ç¼–å·è¡Œ
                count += 1
        return count
    
    def _count_original_dialogues(self, content: str) -> int:
        """ç»Ÿè®¡åŸå§‹å¯¹è¯æ•°é‡"""
        # æŒ‰ SRT ä¸‰è¡Œå—ç»Ÿè®¡
        return len(self._parse_srt_like(content))

    def _parse_srt_like(self, content: str) -> List[Dict[str, Any]]:
        """è§£æ Step0.1 çš„SRTæ ·å¼æ–‡æœ¬ä¸ºç»“æ„åŒ–åˆ—è¡¨ã€‚"""
        def ts_to_ms(ts: str) -> int:
            # æ ¼å¼: HH:MM:SS,mmm
            try:
                hhmmss, ms = ts.split(',')
                h, m, s = hhmmss.split(':')
                return (int(h)*3600 + int(m)*60 + int(s))*1000 + int(ms)
            except Exception:
                return 0
        lines = content.splitlines()
        i = 0
        items = []
        while i < len(lines):
            if not lines[i].strip():
                i += 1
                continue
            # index
            idx_line = lines[i].strip()
            if not idx_line.isdigit():
                i += 1
                continue
            idx = int(idx_line)
            if i+1 >= len(lines):
                break
            ts_line = lines[i+1].strip()
            start_ts, _, end_ts = ts_line.partition(' --> ')
            if i+2 >= len(lines):
                break
            txt_line = lines[i+2].rstrip('\n')
            # è§£æspeakerä¸text
            speaker = ''
            text = txt_line
            if txt_line.startswith('['):
                r = txt_line.find(']')
                if r != -1:
                    speaker = txt_line[:r+1]
                    text = txt_line[r+1:].lstrip()
            items.append({
                'index': idx,
                'start_ms': ts_to_ms(start_ts.strip()),
                'end_ms': ts_to_ms(end_ts.strip()),
                'speaker': speaker,
                'text': text
            })
            # è·³è¿‡ç©ºè¡Œåˆ†éš”
            i += 4
        return items
    
    def _render_dialogues_as_srt_like(self, dialogues: List[Dict[str, Any]]) -> str:
        """å°†ç»“æ„åŒ– dialogues æ¸²æŸ“ä¸º Step0.1 çš„SRTæ ·å¼æ–‡æœ¬ï¼Œä¿æŒå®Œå…¨ä¸€è‡´æ ¼å¼ã€‚
        æœŸæœ›è¾“å‡ºï¼š
        index\n
        HH:MM:SS,mmm --> HH:MM:SS,mmm\n
        [Speaker] text\n
        ï¼ˆç©ºè¡Œåˆ†éš”ï¼‰
        """
        def ms_to_ts(ms: int) -> str:
            ms = max(0, int(ms))
            s, milli = divmod(ms, 1000)
            m, sec = divmod(s, 60)
            h, minute = divmod(m, 60)
            return f"{h:02d}:{minute:02d}:{sec:02d},{milli:03d}"

        lines = []
        # æŒ‰ index æ’åºï¼Œä¿è¯é¡ºåºä¸€è‡´
        for item in sorted(dialogues, key=lambda x: int(x.get('index', 0))):
            start_ms = int(item.get('start_ms', 0))
            end_ms = int(item.get('end_ms', start_ms + 1000))
            spk = item.get('speaker', '').strip()
            text = item.get('text', '').strip()
            # ä¿éšœ speaker ä»¥ [..] åŒ…è£¹
            if spk and not spk.startswith('['):
                spk = f"[{spk}]"
            idx = int(item.get('index', 0))
            lines.append(str(idx))
            lines.append(f"{ms_to_ts(start_ms)} --> {ms_to_ts(end_ms)}")
            lines.append(f"{spk} {text}".rstrip())
            lines.append("")
        return "\n".join(lines).rstrip() + "\n"

    def _generate_statistics(self, results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        total_episodes = len(results)
        success_count = len([r for r in results if r.get("status") == "success"])
        failed_count = len([r for r in results if r.get("status") == "failed"])
        already_exists_count = len([r for r in results if r.get("status") == "already_exists"])
        
        total_original_dialogues = sum(r.get("original_dialogues", 0) for r in results)
        total_calibrated_dialogues = sum(r.get("calibrated_dialogues", 0) for r in results)
        
        avg_calibration_rate = 0
        if success_count > 0:
            calibration_rates = [r.get("calibration_rate", 0) for r in results if r.get("status") == "success"]
            avg_calibration_rate = sum(calibration_rates) / len(calibration_rates) if calibration_rates else 0
        
        return {
            "total_episodes": total_episodes,
            "success_count": success_count,
            "failed_count": failed_count,
            "already_exists_count": already_exists_count,
            "success_rate": (success_count / total_episodes * 100) if total_episodes > 0 else 0,
            "total_original_dialogues": total_original_dialogues,
            "total_calibrated_dialogues": total_calibrated_dialogues,
            "avg_calibration_rate": avg_calibration_rate
        }

    def _build_initial_assignment(self, episode_id: str) -> Dict[str, str]:
        """ä¼˜å…ˆä»å½“é›†ç‹¬ç«‹ CSV æ–‡ä»¶æ„å»º initial speaker æ˜ å°„ï¼Œå›é€€åˆ°å…¨å±€å›¾è°±ã€‚
        è¿”å›: { spk_full_id æˆ– [spk_X] : canonical_name }
        """
        mapping: Dict[str, str] = {}
        
        # 1. ä¼˜å…ˆå°è¯•è¯»å–å½“é›†ç‹¬ç«‹çš„ 0_3_speaker_hints.csv
        ep_hints_csv = os.path.join(self.config.project_root, episode_id, '0_3_speaker_hints.csv')
        if os.path.exists(ep_hints_csv):
            try:
                import csv
                with open(ep_hints_csv, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        spk = row.get('spk_full_id', '').strip()
                        cand = row.get('candidate', '').strip()
                        try:
                            conf = float(row.get('confidence', 0) or 0)
                        except (ValueError, TypeError):
                            conf = 0
                        sticky = row.get('sticky', '').lower() in ['true', '1', 'yes']
                        
                        if not spk or not cand:
                            continue
                        
                        # é‡‡ç”¨ç­–ç•¥ï¼šä¼˜å…ˆ stickyï¼›å…¶æ¬¡é«˜ç½®ä¿¡åº¦>=0.6ï¼›æœ€åæ˜¯æ¥è‡ª character_alias çš„æ˜ å°„
                        take = False
                        if sticky:
                            take = True
                        elif conf >= 0.6 and spk not in mapping:
                            take = True
                        elif conf == 0 and spk not in mapping:  # æ¥è‡ª character_alias çš„æ˜ å°„ï¼ˆconfidence ä¸ºç©ºï¼‰
                            take = True
                        
                        if take:
                            # åŒæ—¶ç™»è®°å»æ‹¬å·ä¸å¸¦æ‹¬å·ä¸¤ç§ keyï¼Œä¾¿äºå›é€€æ—¶æ£€ç´¢
                            mapping[spk] = cand
                            if spk.startswith('[') and spk.endswith(']'):
                                k = spk[1:-1]
                                mapping.setdefault(k, cand)
                            elif not spk.startswith('['):
                                mapping.setdefault(f'[{spk}]', cand)
                
                log.info(f"âœ… ä»å½“é›†æ–‡ä»¶åŠ è½½æ˜ å°„: {ep_hints_csv} ({len(mapping)} æ¡)")
                return mapping
            except Exception as e:
                log.info(f"âš ï¸ è¯»å–å½“é›†æ–‡ä»¶å¤±è´¥: {e}")
        
        # 2. å›é€€åˆ°å…¨å±€å›¾è°±
        if not self.global_graph:
            return mapping
        per_eps = self.global_graph.get('per_episode') or []
        for e in per_eps:
            if e.get('episode_id') != episode_id:
                continue
            hints = e.get('speaker_alignment_hints') or []
            for h in hints:
                spk = h.get('spk_full_id') or ''
                cand = h.get('candidate') or ''
                conf = h.get('confidence') or 0
                sticky = bool(h.get('sticky'))
                # é‡‡ç”¨ç­–ç•¥ï¼šä¼˜å…ˆ stickyï¼›å…¶æ¬¡é«˜ç½®ä¿¡åº¦>=0.6
                if not spk or not cand:
                    continue
                take = False
                if sticky:
                    take = True
                elif conf >= 0.6 and spk not in mapping:
                    take = True
                if take:
                    # åŒæ—¶ç™»è®°å»æ‹¬å·ä¸å¸¦æ‹¬å·ä¸¤ç§ keyï¼Œä¾¿äºå›é€€æ—¶æ£€ç´¢
                    mapping[spk] = cand
                    if spk.startswith('[') and spk.endswith(']'):
                        k = spk[1:-1]
                        mapping.setdefault(k, cand)
                    elif not spk.startswith('['):
                        mapping.setdefault(f'[{spk}]', cand)
        
        log.info(f"âœ… ä»å…¨å±€å›¾è°±åŠ è½½æ˜ å°„: {len(mapping)} æ¡")
        return mapping



    def _get_episode_whitelist(self, episode_id: str) -> set:
        """ä»å…¨å±€å›¾è°±ä¸­è·å–å½“é›†å…è®¸çš„è§’è‰²ç™½åå•ï¼ˆprotagonists + supporting æ ‡ç­¾ï¼‰ã€‚"""
        names = set()
        if not self.global_graph:
            return names
        for e in self.global_graph.get('per_episode', []) or []:
            if e.get('episode_id') != episode_id:
                continue
            for p in e.get('protagonists', []) or []:
                cn = p.get('canonical_name')
                if cn:
                    names.add(cn)
            for s in e.get('supporting', []) or []:
                label = s.get('label')
                if label:
                    names.add(label)
        return names

    def _build_episode_alias_map(self, episode_id: str) -> Dict[str, str]:
        """ä»…åŸºäºå½“é›† speaker_alignment_hints æ„å»ºæ˜ å°„ï¼Œæ´¾ç”Ÿå»é™¤ _epN çš„ spk å˜ä½“ï¼Œå«å¸¦/ä¸å¸¦æ‹¬å·ã€‚"""
        mapping: Dict[str, str] = {}
        if not self.global_graph:
            return mapping
        try:
            ep_num = int(episode_id.split('_')[-1])
            ep_suffix = f"_ep{ep_num}"
        except Exception:
            ep_suffix = None
        import re as _re
        for e in self.global_graph.get('per_episode', []) or []:
            if e.get('episode_id') != episode_id:
                continue
            for h in e.get('speaker_alignment_hints', []) or []:
                spk = h.get('spk_full_id') or ''
                cand = h.get('candidate') or ''
                if not spk or not cand:
                    continue
                # åŸå§‹é”®
                mapping[spk] = cand
                if not spk.startswith('['):
                    mapping[f'[{spk}]'] = cand
                else:
                    inner = spk[1:-1]
                    mapping[inner] = cand
                # å»é™¤ _epN æ´¾ç”Ÿ
                base = spk[1:-1] if (spk.startswith('[') and spk.endswith(']')) else spk
                base_no_ep = _re.sub(r'_ep\d+$', '', base)
                if base_no_ep and base_no_ep != base:
                    mapping.setdefault(base_no_ep, cand)
                    mapping.setdefault(f'[{base_no_ep}]', cand)
        return mapping

    def _load_manual_overrides(self) -> Dict[str, Dict[str, str]]:
        """è¯»å–å…¨å±€æ‰‹å·¥è¦†ç›–æ–‡ä»¶ global/manual_alias_overrides.json
        æœŸæœ›ç»“æ„ï¼š{ "episode_001": {"spk_0": "æ—ç™½", "spk_1_ep1": "é¡¾å‘æ™´"}, ... }
        """
        overrides_path = os.path.join(self.config.project_root, 'global', 'manual_alias_overrides.json')
        if not os.path.exists(overrides_path):
            return {}
        try:
            with open(overrides_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            # ç»Ÿä¸€é”®ä¸ºå­—ç¬¦ä¸²
            norm = {}
            for ep, m in (data or {}).items():
                if not isinstance(m, dict):
                    continue
                norm[ep] = {str(k): str(v) for k, v in m.items()}
            return norm
        except Exception:
            return {}


if __name__ == "__main__":
    from new_pipeline.core import PipelineConfig
    config = PipelineConfig()
    step = Step0_4SpeakerCalibration(config)
    result = step.run()
    log.info(f"æœ€ç»ˆç»“æœ: {result}")
